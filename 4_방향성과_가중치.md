# 4.3 페이지 랭크
⸻

1. 페이지랭크(PageRank)란?

원래 구글이 웹 페이지의 중요도를 계산하기 위해 만든 알고리즘이야.
핵심 아이디어는 “중요한 페이지로부터의 링크는 그 자체로 가치 있는 추천” 이라는 거지.
즉, 단순히 링크 개수가 많다고 좋은 게 아니라, 누가 링크를 줬는지가 훨씬 중요해.

⸻

2. 기본 아이디어
* 노드: 웹 페이지(또는 네트워크의 개체)
* 링크: 한 페이지에서 다른 페이지로 가는 연결
* 각 노드의 점수(PageRank)는 다른 노드들이 준 점수의 일부를 모아 만든 값.
* 모든 점수는 네트워크 전체에서 순환하며, 시간이 지나면 안정된 값(steady state) 에 도달해.

⸻

3. 수학적 표현

기본 페이지랭크 공식은 다음과 같아.

$$PR(i) = \frac{1-d}{N} + d \sum_{j \in M(i)} \frac{PR(j)}{L(j)}$$

여기서:
* $PR(i)$ : 노드 $i$의 페이지랭크 점수
* $N$ : 전체 노드 수
* $M(i)$ : 노드 $i$로 링크를 주는 노드 집합
* $L(j)$ : 노드 $j$가 가진 아웃링크(Out-degree) 개수
* $d$ : 감쇠 계수(damping factor), 보통 0.85 정도
* $\frac{1-d}{N}$ : 모든 노드에 랜덤 점프 확률을 균등하게 분배하는 항

⸻

4. 행렬 표현

네트워크를 전이 확률 행렬(transition probability matrix) $P$로 표현하면:

$$\mathbf{PR} = dP \mathbf{PR} + \frac{1-d}{N}\mathbf{1}$$

여기서:
* $\mathbf{PR}$ : 페이지랭크 벡터 (각 노드의 $PR$ 값)
* $\mathbf{1}$ : 모든 원소가 1인 벡터
* 이 식을 반복 계산하면 PR이 수렴해.

⸻

5. 계산 과정 (Iterative Method)
	1.	모든 노드의 PR 값을 \frac{1}{N}으로 초기화.
	2.	위의 식을 이용해 모든 노드의 PR을 동시에 갱신.
	3.	이전 PR 벡터와 새 PR 벡터의 차이가 작아질 때까지 반복.

⸻

💡 직관
* 링크를 많이 받은 노드가 중요해 보이지만, 중요한 노드로부터의 링크는 훨씬 더 큰 영향력을 준다.
* damping factor $d$는 “무작위로 다른 페이지로 이동하는 확률”을 반영해서, dead end(아웃링크 없는 노드) 문제를 해결한다.

⸻

# 4.6 공동 발생 네트워크

공동 발생 네트워크는 두 개체가 같은 맥락 안에서 자주 함께 등장하는 관계를 네트워크로 표현한 것.

**예시**

* 언어학: 텍스트에서 단어 A와 B가 같은 문장, 같은 문단, 또는 같은 윈도우 크기 내에서 등장 → 두 단어를 연결
* 생물정보학: 동일한 논문/실험에서 같은 단백질이나 유전자가 언급 → 두 유전자 노드 연결
* 생태학: 서로 같은 지역에서 발견되는 동식물 종 → 공동 발생 링크 형성
* SNS 분석: 같은 이벤트나 채팅방에서 자주 함께 언급되는 사람들 → 사회 연결망 형성


# 4.7 가중치의 불균일도

두 노드 사이에 링크가 있는 동일한 상황에서도 링크의 가중치가 다르다면 그 두 노드 사이의 관련성은 매우 다를 수 있다.

## 4.7.2 링크 필터링

네트워크를 정리하는 가장 간단한 방법은 가중치가 어떤 threshold 보다 작은 모든 링크를 제거해 버리는 것이다. 그러나 이 방법은 가중치가 불균형한 경우 특정 threshold를 찾는 것이 어렵다. 즉, 연결강도가 낮은 노드의 경우에는 가중치가 낮은 링크도 중요할 수 있지만, 연결강도가 높은 노드에서는 같은 가중치를 가진 노드가 중요하지 않을 수도 있다.

이를 위한 한가지 방법은 노드의 degree 또는 연결 강도에 따라 서로 상대적인 threshold를 선택하는 것이다. 예를 들면 노드의 가중치 중에 가장 큰 10%의 링크만 남기는 방식이다. 

그러나 이런 방법에도 불구하고 중요한 링크를 보존하고 그렇지 않은 링크를 제거했는지 확신 할 수 없다. 좀더 원리적인 방법은 네트워크의 백본(Backbone)을 찾는 것이다. 즉, 각 노드의 연결강도 중 불균형적으로 많은 비율의 연결을 담당하는 링크를 찾는 것이다.

> <span style="color:blue">네트워크 백본</span>
>
> 링크 가중치가 매우 넓게 분포된 네트워크에서 링크를 정리하기 위해 전역적 문턱값을 사용하는 것은 부적절하다. 대신, 각 노드에 대해 가중치들의 차이를 사용해 대부분의 가중치를 담당하는 링크를 보존할 수 있다. degree가 $k_i$이고 연결강도가 $s_i$인 노드 $i$가 주어지면 합이 $s_i$와 같다는 제약 조건하에서 가중치가 $i$에 붙어있는 $k_i$개 링크에 무작위로 분포되어 있다는 영 모델(null model)에 대해 링크의 중요도를 평가해보는 것이다. 이 가설에서 링크가 $w_{ij}$이상의 가중치를 가질 확률은 다음과 같다. 
> $$p_{ij} = \left(1 - \frac{w_{ij}}{s_i} \right)^{k_i - 1}$$
> 따라서 링크 $ij$가 가중치 $w_{ij}$를 갖는다면 위의 식으로부터 그러한 값이 영 모델과 일치할 확률 $p_{ij}$를 계산 할 수 있다. 원하는 신뢰수준을 나타내는 매개변수를 $\alpha$라고 했을 때, $p_{ij} < \alpha$를 만족하면 링크 $ij$를 유지하고 그렇지 않으면 제거한다. 기준이 되는 $\alpha$값이 작을 수록 더 적은 수의 링크가 보존됨으로 네트워크가 덜 조밀해 진다. 상황에 따라 (얼마나 더 공격적을 링크를 제거하고 싶은지에 따라) $\alpha$값을 정한다. 이렇게 필터링하는 과정을 통해 네트워크의 필수적인 구조와 전반적인 속성을 보존하고 있는 **network backbone**(네트워크 백본)을 추출할 수 있다.

좋아, 그 $k_i - 1$ 지수가 왜 확률 계산에 들어가는지 하나씩 풀어서 얘기해 줄게.
이건 사실 영 모델(null model) 에서 확률 분포를 가정했을 때의 누적분포(CDF) 계산 결과야.

⸻

1. 영 모델의 가정

노드 $i$의 연결 강도 $s_i$가 $k_i$개의 링크에 무작위로 나눠져 있다고 가정해.
* 즉, $w_{ij}$ 값은 그냥 랜덤하게 나눠진 몫 중 하나.
* 각 링크의 가중치는 $0$ 이상이고, 전부 합치면 $s_i$가 됨.
* 이때 “무작위”는 균등하게 나눈다는 뜻이 아니라, 확률적으로 아무 쪽으로나 갈 수 있다는 의미야.

⸻

2. 한 링크의 가중치가 $w_{ij}$ 이상일 확률

전체 강도 $s_i$ 중 한 링크가 $w_{ij}$ 이상 차지하려면,
나머지 $k_i-1$개의 링크가 차지하는 합이 $s_i - w_{ij}$ 이하여야 해.

영 모델에서는 가중치 비율이 균일 분포한다고 보면,
“한 링크가 $w_{ij}$ 이상”이라는 조건은
“나머지 $k_i - 1$개의 링크가 차지하는 비율이 $1 - \frac{w_{ij}}{s_i}$” 이하”와 동일.

⸻

3. 확률 계산 아이디어

남은 $k_i - 1$개의 링크 각각이 비율 $(1 - \frac{w_{ij}}{s_i})$ 안에 들어야 하니까,
각 링크의 비율이 독립적으로 랜덤하게 배분된다고 치면:

$$p_{ij} = \left( 1 - \frac{w_{ij}}{s_i} \right)^{k_i - 1}$$

* $1 - \frac{w_{ij}}{s_i}$ : 남는 강도의 비율
* 지수 $k_i - 1$ : 그 남은 강도를 공유해야 하는 다른 링크 수

이 값이 “영 모델 하에서 이 정도 이상 강도를 가진 링크가 나올 확률”이 되는 거야.

⸻

4. 직관적으로 보면
* 연결이 많을수록 ($k_i$ 큼) 한 링크가 차지하는 강도 비율이 커지는 건 우연히 발생하기 어려움 → 확률 $p_{ij}$ 작아짐.
* $w_{ij}$가 크면 $\frac{w_{ij}}{s_i}$가 커져서 남는 비율이 작아짐 → 역시 $p_{ij}$ 작아짐.
* 그래서 $p_{ij}$가 작으면 “이건 단순 랜덤으로는 잘 안 나오는 큰 값”이라서, 백본에 남김.

⸻


